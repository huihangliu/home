---
layout: 	post
title:  	"Model Averaging when Over-fitting"
date:   	2021-03-12
categories: statistics, causality
visible:	false
---

**模型**: $$y=\sum_{k=1}^{\infty} \beta_{k} x_{k} + e$$. 这种假设是合理的, 例如使用傅里叶基函数或者小波基函数对非参数模型进行回归/预测. 

**目标**: 在**模型误设定**情形下进行**预测**. 

**假设**: 我们观测到的数据为 $$\{y_i ; x_{i1},\dots,x_{ip}\}_{i=1}^{n}$$, 其中 $$y_i$$ 是第 $$i$$ 个响应变量的样本观测值; $$x_{i1},\dots,x_{ip}$$是所有与 $$y$$ 相关的变量及其非线性组合(某种基函数), 并且 $$p>>n$$. 
注意到, 上述假设与传统的模型平均*不同*. 传统的模型平均都假设候选模型维度是小于样本数 $$n$$, 估计时使用的是OLS方法. 然而, 在这种假设下, <u>传统的模型平均是失效的(??)</u>. 分析如下. 

**分析**: 由于所有模型都是误设定的, 即不存在真实模型, 根据已有的模型平均理论 (如 Fang Fang, 2021+, "An asymptotic theory for linear model averaging"), 我们应该尽可能地使用最多的变量, 即尽量选择距离真实模型最近的候选模型. 

- 如果是嵌套的模型, 那么我们应该直接选择最复杂的模型. 
- 但是由于超高维 (甚至是无穷维) 假设, 而**不**是**稀疏**的, 我们没有理由选择一些约简的模型, 使得他们的变量个数小于 $$n$$. 我们还是应该秉持*使用最接近真实模型的模型*这个想法, 即**插值**, 因为插值是我们已知的最充分地使用样本信息的 (一类) 方法. 当然, 变量数目还是太多了, 插值也不唯一. 我们有必要从众多插值方法中, 挑选一种. 

**已有的工作**: 在线性模型中有非常明显的**双下降 (double descent)** 现象, 我使用 LSE (M-P 广义逆替代原本的矩阵逆运算) 对样本进行插值, 没有使用任何变量选择步骤, 逐渐使用越来越多的样本就可以让测试误差逐渐下降到 0 (理论需要核实). 这个例子说明, 在非参数回归中, 我们应该选择尽可能多的变量 (甚至是无穷个变量) 对样本进行<u>具有压缩效应</u>的插值. 详细情况请参考我的[另一篇笔记][dd]. 一个很自然的想法: 在插值时, 使用不同的*压缩方法*会有不同的结果. 例如我在文中使用的是具有最小 $$\ell_2$$ 范数的回归系数. 可以考虑其他的压缩方法如 $$\ell_0$$, $$\ell_1$$ 或者其他的变量选择领域中常用的各种方法. 

**可能的问题**: 

1. 无论我们选择什么样的压缩方法, 由于使用的任然是插值, 训练误差严格为 $$0$$. 所以变量选择常用的 IC 准则应该是不能使用的 (除非我们根据先验信息重新推导 BIC). 我认为可以使用 CV 的方法, 但是这会损失部分训练样本 (这部分样本用于验证), 但由于是线性回归问题, 所以折数较大的 CV 也是可以的, 甚至是 Leave-one-out CV. 
2.  $$\ell_0$$, $$\ell_1$$ 的系数压缩方法, 可能不方便计算, 不像 M-P 广义逆这样简单. 但应该是可以在软件算法上实现的. 
3. 理论目标是什么? 如何证明模型平均相关的理论?  

**模型平均估计**: 

- 候选模型: 使用不同系数压缩方法的插值. 由于使用的向量范数不同, 至少有上述 3 种. 假设有 $$M$$ 个候选模型. 每个候选模型得到的估计量记作 $$\widehat{\boldsymbol{\beta}}^{(m)}=(\widehat{\beta}^{(m)}_1,\dots, \widehat{\beta}^{(m)}_p)^T$$.
- 模型平均形式:  $$\widehat{\mu}_i =\sum_{m=1}^{M} w_m \widehat{\mu}^{(m)}=\sum_{m=1}^{M} \sum_{k=1}^{\infty} w_m \widehat{\beta}_{k}^{(m)} x_{ik}$$, 本质上是在回归系数上加权. 
- 权重计算方式: CV. 



## Reference

[dd]: https://huihangliu.github.io/ldd/	"Linear  Double  Descent"